{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c925ac8a",
   "metadata": {},
   "source": [
    "# COMP0173: Coursework 2\n",
    "\n",
    "The paper HEARTS: A Holistic Framework for Explainable, Sustainable, and Robust Text Stereotype Detection by Theo King, Zekun Wu et al. (2024) presents a comprehensive approach to analysing and detecting stereotypes in text [1]. The authors introduce the HEARTS framework, which integrates model explainability, carbon-efficient training, and accurate evaluation across multiple bias-sensitive datasets. By using transformer-based models such as ALBERT-V2, BERT, and DistilBERT, this research project demonstrates that stereotype detection performance varies significantly across dataset sources, underlining the need for diverse evaluation benchmarks. The paper provides publicly available datasets and code [2], allowing full reproducibility and offering a standardised methodology for future research on bias and stereotype detection in Natural Language Processing (NLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068fd33",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "All figures produced during this notebook are stored in the project’s `/COMP0173_Figures` directory.\n",
    "The corresponding LaTeX-formatted performance comparison tables, including ALBERT-V2, BERT, and DistilBERT are stored in `/COMP0173_PDF`, with the compiled document available as `COMP0173-CW2-TABLES.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279720f4",
   "metadata": {},
   "source": [
    "# Technical Implementation (70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# pip install -r requirements.txt\n",
    "# pip install transformers\n",
    "# pip install --upgrade transformers\n",
    "# pip install --upgrade tokenizers\n",
    "# pip install -U sentence-transformers\n",
    "# pip install natasha\n",
    "# pip install datasets\n",
    "# pip install --user -U nltk\n",
    "# conda install -c anaconda nltk\n",
    "# pip install --upgrade openai pandas tqdm\n",
    "# pip install dotenv\n",
    "# python -m spacy download ru_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pip setuptools wheel\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_trf\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download ru_core_news_lg\n",
    "\n",
    "# # GPU\n",
    "# pip install -U 'spacy[cuda12x]'\n",
    "# # GPU - Train Models\n",
    "# pip install -U 'spacy[cuda12x,transformers,lookups]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries \n",
    "import random, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(23)\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"pkg_resources is deprecated as an API\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526aa252-67bc-4800-a639-661ef2b90b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import importlib.util, pathlib\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "from importlib import reload\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import difflib\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForMaskedLM, XLMWithLMHeadModel\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import platform\n",
    "from datasets import Dataset\n",
    "# import spacy \n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5855d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"Exploratory Data Analysis\")\n",
    "sys.path.append(\"Model Training and Evaluation\")\n",
    "\n",
    "from Initial_EDA import (\n",
    "    prepare_target_variable_distribution,\n",
    "    prepare_group_distribution,\n",
    "    prepare_text_length_analysis,\n",
    "    create_word_cloud\n",
    ")\n",
    "\n",
    "from Sentiment_Toxicity_Analysis_Ru import analyse_sentiment_and_regard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the GPU host (UCL access)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# # Path\n",
    "# import os\n",
    "# os.chdir(\"/tmp/HEARTS-Text-Stereotype-Detection\")\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf84d7",
   "metadata": {},
   "source": [
    "## Part 4: Adapt the model architecture and training pipeline to your local context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b04a90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_chart_domain(df, column, name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot the percentage distribution of social-group domains as a styled pie chart.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing a categorical column representing social domains.\n",
    "    column : str, optional\n",
    "        Name of the column in `df` holding domain labels. \n",
    "        \n",
    "    column : str, optional\n",
    "        Name of the dataset. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays a pie chart visualising the proportional distribution of categories.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The function applies a custom colour palette tailored for the RuBias dataset \n",
    "    (gender, class, nationality, LGBTQ). Any unseen categories default to grey.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute relative frequency (%) of categories\n",
    "    domain_counts = df[column].value_counts(normalize=True) * 100\n",
    "    labels = domain_counts.index\n",
    "    sizes = domain_counts.values\n",
    "\n",
    "    # Predefined colour palette\n",
    "    color_map = {\n",
    "        'gender':      \"#CA5353\",  \n",
    "        'profession':  \"#F1A72F\",  \n",
    "        'nationality': \"#559A67\",  \n",
    "        'lgbtq':       \"#527BCD\",  \n",
    "    }\n",
    "    # Assign colours; fallback to grey for unknown labels\n",
    "    colors = [color_map.get(lbl, 'grey') for lbl in labels]\n",
    "\n",
    "    # Create compact, high-resolution figure\n",
    "    plt.figure(figsize=(5.5, 4), dpi=155)\n",
    "\n",
    "    # Draw pie chart with formatted percentages\n",
    "    wedges, texts, autotexts = plt.pie(\n",
    "        sizes,\n",
    "        labels=None,\n",
    "        autopct='%1.1f%%',\n",
    "        pctdistance=0.55,\n",
    "        startangle=90,\n",
    "        colors=colors,\n",
    "        wedgeprops={'linewidth': 2, 'edgecolor': 'white'}\n",
    "    )\n",
    "\n",
    "    # Style displayed percentage numbers\n",
    "    for t in autotexts:\n",
    "        t.set_fontsize(10)\n",
    "        t.set_color(\"black\")\n",
    "\n",
    "    # Title\n",
    "    plt.title(f\"Social Group Distribution: {name}\", fontsize=16)\n",
    "\n",
    "    # Legend placed to the right of the figure\n",
    "    plt.legend(\n",
    "        wedges,\n",
    "        labels,\n",
    "        title=\"Domain\",\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1.02, 0.5),\n",
    "        fontsize=11,\n",
    "        title_fontsize=12\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(texts: pd.Series) -> pd.Series:\n",
    "    \n",
    "    \"\"\"\n",
    "    Normalise Russian stereotype strings.\n",
    "\n",
    "    Operations\n",
    "    ----------\n",
    "    - remove the phrases \", как и все люди,\" and \", как и все остальные,\"\n",
    "    - lowercase\n",
    "    - remove punctuation (including comma)\n",
    "    - replace '-' and '—' with spaces\n",
    "    - collapse multiple spaces\n",
    "    - normalise 'ё' → 'е'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : pd.Series\n",
    "        Series of raw text strings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Normalised text strings.\n",
    "    \"\"\"\n",
    "\n",
    "    # remove all punctuation except underscore (keep '_' if you use it as a token)\n",
    "    punc = ''.join(ch for ch in string.punctuation if ch not in '_')\n",
    "\n",
    "    # replace '-' and '—' with spaces, remove other punctuation (including commas)\n",
    "    trans_table = str.maketrans('-—', '  ', punc)\n",
    "\n",
    "    PHRASES_TO_REMOVE = [\n",
    "        \"как и все люди\",\n",
    "        \"как и все остальные\",\n",
    "        \"как и другие люди\",\n",
    "        \"как и другие народы\",\n",
    "        \"как и другие нации\" \n",
    "    ]\n",
    "\n",
    "    def _norm(s: str) -> str:\n",
    "        s = str(s)\n",
    "\n",
    "        # remove specific filler phrases\n",
    "        for ph in PHRASES_TO_REMOVE:\n",
    "            s = s.replace(ph, \"\")\n",
    "\n",
    "        # lowercase + strip punctuation\n",
    "        s = s.lower().translate(trans_table)\n",
    "\n",
    "        # collapse multiple spaces\n",
    "        s = \" \".join(s.split())\n",
    "\n",
    "        # normalise ё → е\n",
    "        s = s.replace(\"ё\", \"е\")\n",
    "\n",
    "        return s\n",
    "\n",
    "    return texts.apply(_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rubist(df: pd.DataFrame, text_col: str = \"text\") -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Clean and restructure the augmented RUBIAS dataset.\n",
    "\n",
    "    Steps:\n",
    "    - Drop rows where stereotype_type is missing\n",
    "    - Drop old 'category' column if present\n",
    "    - Rename 'label_level' → 'category'\n",
    "    - Create 'label' column: category_stereotype_type\n",
    "    - Reorder columns to: stereotype_type, text, category, label\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop rows with missing stereotype_type\n",
    "    df = df.dropna(subset=[\"stereotype_type\"])\n",
    "\n",
    "    # Drop old category column if exists\n",
    "    if \"category\" in df.columns:\n",
    "        df = df.drop(columns=[\"category\"])\n",
    "\n",
    "    # Rename label_level → category\n",
    "    df = df.rename(columns={\"label_level\": \"category\"})\n",
    "    \n",
    "    # Format strings\n",
    "    df[text_col] = format_text(df[text_col])\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=\"text\")\n",
    "\n",
    "    # Reorder columns\n",
    "    desired_order = [\"stereotype_type\", text_col, \"category\"]\n",
    "    df = df[desired_order]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grouped_barplot(percent_table, title, color_map):\n",
    "    \n",
    "    \"\"\"\n",
    "    Plot a grouped bar chart with thin bars and spacing.\n",
    "    Clean style, no y-label, no legend title.\n",
    "    \"\"\"\n",
    "\n",
    "    categories = percent_table.index.tolist()\n",
    "    labels = percent_table.columns.tolist()\n",
    "\n",
    "    x = np.arange(len(categories))\n",
    "\n",
    "    total_width = 0.55\n",
    "    width = total_width / max(len(labels), 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 3.5), dpi=200)\n",
    "\n",
    "    # Bars\n",
    "    for i, lab in enumerate(labels):\n",
    "        offsets = x - total_width/2 + (i + 0.5) * width\n",
    "        ax.bar(\n",
    "            offsets,\n",
    "            percent_table[lab].values,\n",
    "            width=width * 0.75,\n",
    "            label=lab,\n",
    "            color=color_map.get(lab, \"grey\"),\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "\n",
    "    # Axis Style\n",
    "    ax.set_facecolor(\"white\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories, fontsize=11)\n",
    "\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_yticks(np.arange(0, 101, 10))\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    ax.set_ylabel(\"\")  # removed y-label\n",
    "\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda v, pos: f\"{int(v)}%\"))\n",
    "\n",
    "    ax.set_title(title, fontsize=15, pad=12)\n",
    "\n",
    "    ax.yaxis.grid(True, linestyle='-', alpha=0.13)\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.15),\n",
    "        ncol=len(labels),\n",
    "        frameon=False,\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f403137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_by_category(df, category_col=\"category\", sentiment_col=\"sentiment\"):\n",
    "\n",
    "    tab = pd.crosstab(df[category_col], df[sentiment_col], normalize=\"index\") * 100\n",
    "\n",
    "    tab = tab.reindex(\n",
    "        index=[\"stereotype\", \"neutral\", \"unrelated\"],\n",
    "        columns=[\"positive\", \"neutral\", \"negative\"]\n",
    "    ).fillna(0)\n",
    "\n",
    "    _grouped_barplot(tab, \"Sentiment Classifications by Category (RuBIST)\", SENTIMENT_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_toxic_by_category(df, category_col=\"category\", toxic_col=\"regard\"):\n",
    "\n",
    "    tab = pd.crosstab(df[category_col], df[toxic_col], normalize=\"index\") * 100\n",
    "\n",
    "    tab = tab.reindex(\n",
    "        index=[\"stereotype\", \"neutral\", \"unrelated\"],\n",
    "        columns=[\"toxic\", \"non_toxic\"]\n",
    "    ).fillna(0)\n",
    "\n",
    "    _grouped_barplot(tab, \"Toxicity Classifications by Category (RuBIST)\", TOXIC_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_for_stereotypes_by_group(df,\n",
    "                                            category_col=\"category\",\n",
    "                                            group_col=\"stereotype_type\",\n",
    "                                            sentiment_col=\"sentiment\"):\n",
    "\n",
    "    subset = df[df[category_col] == \"stereotype\"]\n",
    "\n",
    "    tab = pd.crosstab(subset[group_col], subset[sentiment_col], normalize=\"index\") * 100\n",
    "\n",
    "    tab = tab.reindex(\n",
    "        index=[\"gender\", \"profession\", \"nationality\", \"lgbtq\"],\n",
    "        columns=[\"positive\", \"neutral\", \"negative\"]\n",
    "    ).fillna(0)\n",
    "\n",
    "    _grouped_barplot(\n",
    "        tab,\n",
    "        \"Proportion of Sentiment Classifications\\nfor Stereotypical Sentences - By Group\",\n",
    "        SENTIMENT_COLORS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_toxic_for_stereotypes_by_group(df,\n",
    "                                        category_col=\"category\",\n",
    "                                        group_col=\"stereotype_type\",\n",
    "                                        toxic_col=\"regard\"):\n",
    "\n",
    "    subset = df[df[category_col] == \"stereotype\"]\n",
    "\n",
    "    tab = pd.crosstab(subset[group_col], subset[toxic_col], normalize=\"index\") * 100\n",
    "\n",
    "    tab = tab.reindex(\n",
    "        index=[\"gender\", \"profession\", \"nationality\", \"lgbtq\"],\n",
    "        columns=[\"toxic\", \"non_toxic\"]\n",
    "    ).fillna(0)\n",
    "\n",
    "    _grouped_barplot(\n",
    "        tab,\n",
    "        \"Proportion of Toxicity Classifications\\nfor Stereotypical Sentences - By Group\",\n",
    "        TOXIC_COLORS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f984125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_semantic_duplicates(\n",
    "    df: pd.DataFrame,\n",
    "    text_col: str = \"text\",\n",
    "    group_col: str = \"stereotype_type\",\n",
    "    model_name: str = \"DeepPavlov/rubert-base-cased-sentence\",\n",
    "    border_sim: float = 0.98,\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Remove semantically near-duplicate text entries from a dataframe.\n",
    "\n",
    "    This function computes sentence embeddings using a SentenceTransformer\n",
    "    model and identifies near-duplicate sentences based on cosine similarity.\n",
    "    Only sentences belonging to the same group (e.g., same stereotype type)\n",
    "    are compared. For each pair of sentences that exceed the similarity \n",
    "    threshold, the later-indexed entry is removed. Detected duplicates \n",
    "    are printed to stdout.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe containing at least the text column and optionally a \n",
    "        grouping column.\n",
    "    text_col : str, default \"text\"\n",
    "        Name of the column containing raw text to evaluate for duplicates.\n",
    "    group_col : str, default \"stereotype_type\"\n",
    "        Column name determining groups within which similarity comparisons \n",
    "        are performed. Sentences from different groups are never compared.\n",
    "    model_name : str, default \"DeepPavlov/rubert-base-cased-sentence\"\n",
    "        Identifier of a SentenceTransformer model used to compute embeddings.\n",
    "    border_sim : float, default 0.98\n",
    "        Cosine similarity threshold above which two sentences are considered\n",
    "        near-duplicates. Must be in the range [0, 1].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A cleaned dataframe with near-duplicate rows removed and the index\n",
    "        reset.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function prints each detected near-duplicate pair, including the\n",
    "      kept sentence, removed sentence, and similarity score.\n",
    "    - Duplicate detection is greedy: the earliest occurrence is preserved,\n",
    "      and any later duplicates are removed.\n",
    "    - Performance may degrade for very large datasets due to O(n^2)\n",
    "      pairwise similarity comparisons.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> df_clean = drop_semantic_duplicates(\n",
    "    ...     df,\n",
    "    ...     text_col=\"text\",\n",
    "    ...     group_col=\"stereotype_type\",\n",
    "    ...     border_sim=0.90,\n",
    "    ... )\n",
    "    >>> df_clean.head()\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.reset_index(drop=True).copy()\n",
    "\n",
    "    sent_encoder = SentenceTransformer(model_name)\n",
    "    texts = df[text_col].tolist()\n",
    "    embeddings = sent_encoder.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "    to_remove = set()\n",
    "    n = len(df)\n",
    "\n",
    "    for i in range(n):\n",
    "        if i in to_remove:\n",
    "            continue\n",
    "        for j in range(i + 1, n):\n",
    "            if j in to_remove:\n",
    "                continue\n",
    "\n",
    "            if df.loc[i, group_col] != df.loc[j, group_col]:\n",
    "                continue\n",
    "\n",
    "            sim = util.pytorch_cos_sim(embeddings[i], embeddings[j]).item()\n",
    "\n",
    "            if sim > border_sim:\n",
    "                print(\"-\" * 80)\n",
    "                print(f\"Duplicates Found (Similarity = {sim:.3f})\")\n",
    "                print(f\"Saved [{i}]: {df.loc[i, text_col]}\")\n",
    "                print(f\"Removed [{j}]: {df.loc[j, text_col]}\")\n",
    "                print(\"-\" * 80)\n",
    "\n",
    "                to_remove.add(j)\n",
    "\n",
    "    print(f\"\\nTotal near-duplicates removed: {len(to_remove)}\\n\")\n",
    "\n",
    "    return df.drop(index=list(to_remove)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768697e1",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 1:}$ Justify architectural modifications for new context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ddbf28",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "rubist_aug = pd.read_csv(\"COMP0173_Temp_Data/rubist_aug.csv\", encoding=\"utf-8\")\n",
    "rubist_aug_second= pd.read_csv(\"COMP0173_Temp_Data/rubist_aug_second.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset\n",
    "rubist_aug = clean_rubist(rubist_aug)\n",
    "rubist_aug.head()\n",
    "# Save cleaned final version\n",
    "rubist_aug.to_csv(\"COMP0173_Data/rubist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4045658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset\n",
    "rubist_aug_second = clean_rubist(rubist_aug_second)\n",
    "rubist_aug_second.head()\n",
    "# Save cleaned final version\n",
    "rubist_aug_second.to_csv(\"COMP0173_Data/rubist_second.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8fefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final version \n",
    "rubist = pd.read_csv(\"COMP0173_Data/rubist.csv\", encoding=\"utf-8\")\n",
    "rubist_second = pd.read_csv(\"COMP0173_Data/rubist_second.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afc1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EDA\n",
    "target_dist = prepare_target_variable_distribution(rubist, \"category\")\n",
    "group_dist = prepare_group_distribution(rubist, \"stereotype_type\")\n",
    "text_length = prepare_text_length_analysis(rubist, \"text\")\n",
    "create_word_cloud(rubist, text_col='text', output_filename='rubist_wordcloud.png')\n",
    "\n",
    "# Run EDA\n",
    "target_dist = prepare_target_variable_distribution(rubist_second, \"category\")\n",
    "group_dist = prepare_group_distribution(rubist_second, \"stereotype_type\")\n",
    "text_length = prepare_text_length_analysis(rubist_second, \"text\")\n",
    "create_word_cloud(rubist_second, text_col='text', output_filename='rubist_second_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56762d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment and Toxicity\n",
    "rubist_sentiment = analyse_sentiment_and_regard(rubist, text_col=\"text\")\n",
    "rubist_sentiment.head()\n",
    "rubist_sentiment.to_csv(\"COMP0173_Results/rubist_sentiment\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# Sentiment and Toxicity\n",
    "rubist_second_sentiment = analyse_sentiment_and_regard(rubist, text_col=\"text\")\n",
    "rubist_second_sentiment.head()\n",
    "rubist_second_sentiment.to_csv(\"COMP0173_Results/rubist_second_sentiment\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baed0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubist_sentiment = pd.read_csv(\"COMP0173_Results/rubist_sentiment\", encoding=\"utf-8-sig\")\n",
    "rubist_second_sentiment = pd.read_csv(\"COMP0173_Results/rubist_second_sentiment\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946531e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour maps\n",
    "SENTIMENT_COLORS = {\n",
    "    \"positive\": \"#559A67\",  \n",
    "    \"neutral\":  \"#F1A72F\",  \n",
    "    \"negative\": \"#CA5353\", \n",
    "}\n",
    "\n",
    "TOXIC_COLORS = {\n",
    "    \"toxic\":      \"#CA5353\",\n",
    "    \"non_toxic\":  \"#559A67\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26624ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all four plots\n",
    "plot_sentiment_by_category(rubist_sentiment)\n",
    "plot_toxic_by_category(rubist_sentiment)\n",
    "plot_sentiment_for_stereotypes_by_group(rubist_sentiment)\n",
    "plot_toxic_for_stereotypes_by_group(rubist_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24807036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all four plots\n",
    "plot_sentiment_by_category(rubist_second_sentiment)\n",
    "plot_toxic_by_category(rubist_second_sentiment)\n",
    "plot_sentiment_for_stereotypes_by_group(rubist_second_sentiment)\n",
    "plot_toxic_for_stereotypes_by_group(rubist_second_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d65e7",
   "metadata": {},
   "source": [
    "#### Train models - Logistic Regression (Spacy Russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4259ae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Logistic_Regression_Russian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLogistic_Regression_Russian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (data_loader, train_model, evaluate_model)\n\u001b[1;32m      3\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Logistic_Regression_Russian'"
     ]
    }
   ],
   "source": [
    "from Logistic_Regression_Russian import (data_loader, train_model, evaluate_model)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load and combine relevant datasets\n",
    "train_data_rubist, test_data_rubist = data_loader(csv_file_path='COMP0173_Data/rubist.csv', labelling_criteria='stereotype', dataset_name='rubist', sample_size=1000000, num_examples=5)\n",
    "train_data_rubist_second, test_data_rubist_second = data_loader(csv_file_path='COMP0173_Data/rubist_second.csv', labelling_criteria='stereotype', dataset_name='rubist_second', sample_size=1000000, num_examples=5)\n",
    "\n",
    "\n",
    "# Execute full pipeline for logistic regression tfidf model\n",
    "train_model(train_data_rubist, model_output_base_dir='model_output_LR_tfidf', dataset_name='rubist_trained', feature_type='tfidf', seed=42)\n",
    "evaluate_model(test_data_rubist, model_output_dir='model_output_LR_tfidf/rubist_trained', result_output_base_dir='result_output_LR_tfidf', dataset_name='rubist', feature_type='tfidf', seed=42)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_model(train_data_rubist_second, model_output_base_dir='model_output_LR_tfidf', dataset_name='rubist_second_trained', feature_type='tfidf', seed=42)\n",
    "evaluate_model(test_data_rubist_second, model_output_dir='model_output_LR_tfidf/rubist_second_trained', result_output_base_dir='result_output_LR_tfidf', dataset_name='rubist_second', feature_type='tfidf', seed=42)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Execute full pipeline for logistic regression embedding model\n",
    "train_model(train_data_rubist, model_output_base_dir='model_output_LR_embedding', dataset_name='rubist_trained', feature_type='embedding', seed=42)\n",
    "evaluate_model(test_data_rubist, model_output_dir='model_output_LR_embedding/rubist_trained', result_output_base_dir='result_output_LR_embedding', dataset_name='rubist', feature_type='embedding', seed=42)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_model(train_data_rubist_second, model_output_base_dir='model_output_LR_embedding', dataset_name='rubist_second_trained', feature_type='embedding', seed=42)\n",
    "evaluate_model(test_data_rubist_second, model_output_dir='model_output_LR_embedding/rubist_second_trained', result_output_base_dir='result_output_LR_embedding', dataset_name='rubist_second', feature_type='embedding', seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5379ef",
   "metadata": {},
   "source": [
    "#### Train models - DeepPavlov_rubert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc88fe2-4054-4133-929e-9b1f9386c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/tmp/hf\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/tmp/hf\"\n",
    "os.makedirs(\"/tmp/hf\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BERT_Models_Fine_Tuning_Russian import (data_loader, train_model, evaluate_model)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load and combine relevant datasets\n",
    "train_data_rubist, test_data_rubist = data_loader(csv_file_path='COMP0173_Data/rubist.csv', labelling_criteria='stereotype', dataset_name='rubist', sample_size=1000000, num_examples=5)\n",
    "train_data_rubist_second, test_data_rubist_second = data_loader(csv_file_path='COMP0173_Data/rubist_second.csv', labelling_criteria='stereotype', dataset_name='rubist_second', sample_size=1000000, num_examples=5)\n",
    "\n",
    "# Execute full pipeline for Deepavlov model\n",
    "train_model(train_data_rubist, model_path='DeepPavlov/rubert-base-cased', batch_size=64, epoch=6, learning_rate=2e-5, model_output_base_dir='model_output_deeppavlov_rubert', dataset_name='rubist_trained', seed=42)\n",
    "evaluate_model(test_data_rubist, model_output_dir='model_output_deeppavlov_rubert/rubist_trained', result_output_base_dir='result_output_deeppavlov_rubert', dataset_name='rubist_trained', seed=42)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_model(train_data_rubist_second, model_path='DeepPavlov/rubert-base-cased', batch_size=64, epoch=6, learning_rate=2e-5, model_output_base_dir='model_output_deeppavlov_rubert', dataset_name='rubist_second_trained', seed=42)\n",
    "evaluate_model(test_data_rubist_second, model_output_dir='model_output_deeppavlov_rubert/rubist_second_trained', result_output_base_dir='result_output_deeppavlov_rubert', dataset_name='rubist_second_trained', seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344099e",
   "metadata": {},
   "source": [
    "#### Train models - roberta_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BERT_Models_Fine_Tuning_Russian import (data_loader, train_model, evaluate_model)\n",
    "\n",
    "# Load and combine relevant datasets\n",
    "train_data_rubist, test_data_rubist = data_loader(csv_file_path='COMP0173_Data/rubist.csv', labelling_criteria='stereotype', dataset_name='rubist', sample_size=1000000, num_examples=5)\n",
    "train_data_rubist_second, test_data_rubist_second = data_loader(csv_file_path='COMP0173_Data/rubist_second.csv', labelling_criteria='stereotype', dataset_name='rubist_second', sample_size=1000000, num_examples=5)\n",
    "\n",
    "# Execute full pipeline for Deepavlov model\n",
    "train_model(train_data_rubist, model_path='ai-forever/ruBert-base', batch_size=64, epoch=6, learning_rate=2e-5, model_output_base_dir='model_output_ruberta_base', dataset_name='rubist_trained', seed=42)\n",
    "evaluate_model(test_data_rubist, model_output_dir='model_output_ruberta_base/rubist_trained', result_output_base_dir='result_output_ruberta_base', dataset_name='rubist_trained', seed=42)\n",
    "\n",
    "train_model(train_data_rubist_second, model_path='ai-forever/ruBert-base', batch_size=64, epoch=6, learning_rate=2e-5, model_output_base_dir='model_output_ruberta_base', dataset_name='rubist_second_trained', seed=42)\n",
    "evaluate_model(test_data_rubist_second, model_output_dir='model_output_ruberta_base/rubist_second_trained', result_output_base_dir='result_output_ruberta_base', dataset_name='rubist_second_trained', seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a843b28",
   "metadata": {},
   "source": [
    "#### Train models - FacebookAI/xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ee5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BERT_Models_Fine_Tuning_Russian import (data_loader, train_model, evaluate_model)\n",
    "\n",
    "# Load and combine relevant datasets\n",
    "train_data_rubist, test_data_rubist = data_loader(csv_file_path='COMP0173_Data/rubist.csv', labelling_criteria='stereotype', dataset_name='rubist', sample_size=1000000, num_examples=5)\n",
    "train_data_rubist_second, test_data_rubist_second = data_loader(csv_file_path='COMP0173_Data/rubist_second.csv', labelling_criteria='stereotype', dataset_name='rubist_second', sample_size=1000000, num_examples=5)\n",
    "\n",
    "# Execute full pipeline for Deepavlov model\n",
    "train_model(train_data_rubist, model_path='FacebookAI/xlm-roberta-base', batch_size=64, epoch=6, learning_rate=2e-5, model_output_base_dir='model_output_xlm_roberta_base', dataset_name='rubist_trained', seed=42)\n",
    "evaluate_model(test_data_rubist, model_output_dir='model_output_xlm_roberta_base/rubist_trained', result_output_base_dir='result_output_xlm_roberta_base', dataset_name='rubist_trained', seed=42)\n",
    "\n",
    "train_model(train_data_rubist_second, model_path='FacebookAI/xlm-roberta-base', batch_size=64, epoch=6, learning_rate=2e-5, model_output_base_dir='model_output_xlm_roberta_base', dataset_name='rubist_second_trained', seed=42)\n",
    "evaluate_model(test_data_rubist_second, model_output_dir='model_output_xlm_roberta_base/rubist_second_trained', result_output_base_dir='result_output_xlm_roberta_base', dataset_name='rubist_second_trained', seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40842ea4",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 2:}$ Document hyperparameter tuning process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d59de",
   "metadata": {},
   "source": [
    "## Part 5: Evaluate the adapted model, comparing performance metrics with the original study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6f894",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 1:}$ Compare original vs. adapted model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0eb46",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 2:}$ Use appropriate metrics for problem type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc9723",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 3:}$ Conduct statistical significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a40030",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 4:}$ Analyze failure cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad2c76",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "[1] Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, and Philip Treleaven. 2024.\n",
    "HEARTS: A holistic framework for explainable, sustainable and robust text stereotype detection.\n",
    "arXiv preprint arXiv:2409.11579.\n",
    "Available at: https://arxiv.org/abs/2409.11579\n",
    "(Accessed: 4 December 2025).\n",
    "https://doi.org/10.48550/arXiv.2409.11579\n",
    "\n",
    "[2] Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, and Philip Treleaven. 2024.\n",
    "HEARTS-Text-Stereotype-Detection (GitHub Repository).\n",
    "Available at: https://github.com/holistic-ai/HEARTS-Text-Stereotype-Detection\n",
    "(Accessed: 4 December 2025).\n",
    "\n",
    "[3] Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, and Philip Treleaven. Holistic AI. 2024.\n",
    "EMGSD: Expanded Multi-Group Stereotype Dataset (HuggingFace Dataset).\n",
    "Available at: https://huggingface.co/datasets/holistic-ai/EMGSD\n",
    "(Accessed: 4 December 2025).\n",
    "\n",
    "[4] University College London Technical Support Group (TSG).\n",
    "2025. GPU Access and Usage Documentation.\n",
    "Available at: https://tsg.cs.ucl.ac.uk/gpus/\n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[5] United Nations. 2025. The 2030 Agenda for Sustainable Development. \n",
    "Available at: https://sdgs.un.org/2030agenda \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8f621",
   "metadata": {},
   "source": [
    "[] Natasha. Russian NLP Library (conda-forge distribution). Available at:\n",
    "https://anaconda.org/conda-forge/natasha\n",
    "(Accessed 8 December 2025).\n",
    "\n",
    "[] Anthropic. Claude Artifact. Available at:\n",
    "https://claude.ai/public/artifacts/ab5532d8-7d61-4a98-acec-5cc4236f0d74\n",
    "(Accessed: 8 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c5643",
   "metadata": {},
   "source": [
    "## References: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7ae45",
   "metadata": {},
   "source": [
    "Gender Stereotypes\n",
    "\n",
    "https://adme.media/articles/11-stereotipov-o-muzhchinah-i-zhenschinah-kotorye-davno-ustareli-no-mnogie-s-nimi-tak-i-zhivut-2526726/\n",
    "\n",
    "https://t-j.ru/gender-stereotypes-cases/?utm_referrer=https%3A%2F%2Fwww.google.com%2F\n",
    "\n",
    "https://klinikaexpert.ru/articles/v-yarlykah-lozhnye-stereotipy-o-muzhchinah-i-zhenschinah\n",
    "\n",
    "https://news.zerkalo.io/life/54154.html\n",
    "\n",
    "https://www.sbras.info/articles/editors/gendernye-stereotipy-v-kotorye-pora-perestat-verit\n",
    "\n",
    "https://www.rbc.ua/ukr/styler/rozpovsyudzheni-ta-zastarili-stereotipi-cholovikiv-1709482914.html\n",
    "\n",
    "https://burninghut.ru/stereotipy-o-muzhchinakh-i-zhenshhinakh/\n",
    "\n",
    "https://www.sravni.ru/text/5-stereotipov-o-muzhchinakh-i-zhenshhinakh-kotorye-plokho-vlijajut-na-finansy-semi/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb6af1",
   "metadata": {},
   "source": [
    "Profession Stereotypes\n",
    "\n",
    "https://psy.1sept.ru/article.php?ID=200301712\n",
    "\n",
    "https://peopletalk.ru/article/10-samyh-populyarnyh-stereotipov-o-professiyah-kotorye-besyat/\n",
    "\n",
    "https://adukar.com/by/news/abiturientu/stereotipy-o-professiyah\n",
    "\n",
    "https://kemgmu.ru/about_the_university/news/11672/\n",
    "\n",
    "https://dzen.ru/a/YZ81OX7HcALiVr1k\n",
    "\n",
    "https://nafi.ru/en/analytics/samye-rasprostranennye-stereotipy-rossiyan-ob-it-professiyakh-/\n",
    "\n",
    "https://mosdigitals.ru/blog/pochemu-ne-lyubyat-yuristov-osnovnye-prichiny-i-stereotipy\n",
    "\n",
    "https://medium.com/juris-prudence/%D1%82%D1%80%D0%B0%D0%B4%D0%B8%D1%86%D0%B8%D0%B8-%D1%8E%D1%80%D0%B8%D1%81%D1%82%D0%BE%D0%B2-%D0%BF%D1%80%D0%B0%D0%B2%D0%B4%D0%B0-%D0%B2%D1%8B%D0%BC%D1%8B%D1%81%D0%B5%D0%BB-%D0%B1%D1%83%D0%BB%D1%88%D0%B8%D1%82-cc3de98cdfec\n",
    "\n",
    "https://stereotypes_actors.tilda.ws/\n",
    "\n",
    "https://m.vk.com/wall-181816199_1644\n",
    "\n",
    "https://kovrov.ecvdo.ru/states/stereotipy-o-professii-ekonomista-chto-pravda-a-chto-vymysel\n",
    "\n",
    "https://urzhum.ecvdo.ru/states/razvenchivaem-mify-o-professii-finansista\n",
    "\n",
    "https://azov.ecvdo.ru/states/mify-o-populyarnyh-professiyah?utm_referrer=https%3A%2F%2Fwww.google.com%2F\n",
    "\n",
    "https://igrim.ecvdo.ru/states/mify-i-pravda-o-rabote-v-sfere-obrazovaniya?utm_referrer=https%3A%2F%2Fwww.google.com%2F\n",
    "\n",
    "https://brodude.ru/8-stereotipov-o-rabote-shef-povara/\n",
    "\n",
    "https://www.maximonline.ru/lifestyle/7-glavnykh-mifov-o-rabote-bortprovodnikov-id6443401/\n",
    "\n",
    "https://www.sports.ru/football/blogs/477244.html\n",
    "\n",
    "https://dnmu.edu.ua/old/pro-meditsinu/3633-o-hirurgah\n",
    "\n",
    "https://vc.ru/id3158218/1127046-mify-o-pilotah-ty-tozhe-tak-dumal\n",
    "\n",
    "https://www.psychologies.ru/wellbeing/5-strashnyih-mifov-o-detskom-balete-v-kotoryie-pora-perestat-verit/\n",
    "\n",
    "https://masterok.livejournal.com/11781279.html\n",
    "\n",
    "https://adme.media/articles/10-mifov-o-balete-kotorye-kinoshniki-pridumali-radi-vau-effekta-a-my-i-kupilis-2514646/\n",
    "\n",
    "https://mir24.tv/articles/16379683/8-glavnyh-stereotipov-o-rabote-advokata-merkantilnye-ciniki-ili-professionaly\n",
    "\n",
    "https://omsk.ecvdo.ru/states/mify-o-dizajnerskoj-professii-razbiraemsya-chto-pravda-a-chto-net?utm_referrer=https%3A%2F%2Fwww.google.com%2F\n",
    "\n",
    "https://media.contented.ru/vdohnovenie/kofebrejk/5-mifov-o-dizaynerah/\n",
    "\n",
    "https://ashleyhome.am/ru/blogs/news/steriotipy-o-dizainerax\n",
    "\n",
    "https://lifehacker.ru/7-stereotipov-o-rabote-barmena/\n",
    "\n",
    "https://klepachsv.livejournal.com/24127.html\n",
    "\n",
    "https://www.championat.com/lifestyle/article-4793635-razoblachaem-top-9-stereotipov-o-sportsmenah-pravda-ili-vymysel.html\n",
    "\n",
    "https://krasotuli.com/25199-stereotipy-o-parikmaherskom-dele-razvenchivaem-mify.html\n",
    "\n",
    "https://maycenter.ru/blog/mifi-o-professii-parikmakhera\n",
    "\n",
    "https://m.ok.ru/group/70000000389722/topic/157405964165210?opncmnt\n",
    "https://nacasting.ru/statii/mify-o-rezhisserakh\n",
    "\n",
    "https://omsk.ecvdo.ru/states/mify-o-professii-arhitektora-chto-na-samom-dele-vazhno-dlya-uspeha-v-etoj-sfere\n",
    "\n",
    "http://www.lookatme.ru/flow/posts/fashion-radar/181029-mify-i-realii-o-modelnom-biznese\n",
    "\n",
    "https://rylskova.com/%D0%BC%D0%B8%D1%84%D1%8B-%D0%BE-%D0%BF%D1%80%D0%BE%D1%84%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D1%85-%D1%84%D0%BE%D1%82%D0%BE%D0%B3%D1%80%D0%B0%D1%84%D0%B0%D1%85/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec28403",
   "metadata": {},
   "source": [
    "Nationality/Race Stereotypes\n",
    "\n",
    "https://kuban24.tv/item/10-samyh-rasprostranennyh-stereotipov-o-raznyh-natsionalnostyah\n",
    "\n",
    "https://mir24.tv/articles/16626782/10-stereotipov-ob-indejcah:-razoblachenie-mifov-i-udivitelnye-fakty\n",
    "\n",
    "https://tandem.net/ru/blog/russian-stereotypes-fact-fiction\n",
    "\n",
    "https://tandem.net/ru/blog/british-stereotypes-fact-or-myth\n",
    "\n",
    "https://meschool.ru/poleznoe/top-7-stereotipov-o-britancakh/\n",
    "\n",
    "https://linguacats.com/ru/stati/o-chjom-molchat-frantsuzhenki\n",
    "\n",
    "https://smapse.livejournal.com/699411.html\n",
    "\n",
    "https://francaisclub.ru/%D1%81%D1%82%D0%B5%D1%80%D0%B5%D0%BE%D1%82%D0%B8%D0%BF%D1%8B-%D0%BE-%D1%84%D1%80%D0%B0%D0%BD%D1%86%D1%83%D0%B7%D0%B0%D1%85/\n",
    "\n",
    "https://www.bestprivateguides.com/articles/stereotipi-ob-italyantsah-art-69.php\n",
    "\n",
    "https://maminklub.lv/rebionok/stereotipy-ob-ispantsakh-pravda-i-lozh-623074/\n",
    "\n",
    "https://pikabu.ru/story/stereotipyi_ob_ispantsakh__pravda_i_vyimyisel_6306872\n",
    "\n",
    "https://chetyre-jelania.livejournal.com/197804.html\n",
    "\n",
    "https://www.staypoland.com/ru/poland/stereotipy-o-polshe/\n",
    "\n",
    "https://abea.com.ua/ru/top-10-pravdyvykh-stereotypov-ob-ukrayne-y-ukrayntsakh\n",
    "\n",
    "https://vancouverok.com/15-stereotipov-o-kanadtsah-kotorye-yavlyayutsya-pravdoj/\n",
    "\n",
    "https://nashvancouver.com/6-lozhnih-stereotipov-o-kanadcax/\n",
    "\n",
    "https://amivisa.ru/blog/usa/stereotipy-ob-amerikancax-pravda-i-vymysel/\n",
    "\n",
    "https://www.english-language.ru/articles/informative/stereotipyi-ob-amerikanczax/\n",
    "\n",
    "https://tonkosti.ru/%D0%96%D1%83%D1%80%D0%BD%D0%B0%D0%BB/11_%D0%B4%D0%B8%D0%BA%D0%BE%D0%B2%D0%B0%D1%82%D1%8B%D1%85_%D1%81%D1%82%D0%B5%D1%80%D0%B5%D0%BE%D1%82%D0%B8%D0%BF%D0%BE%D0%B2_%D0%BE_%D1%80%D1%83%D1%81%D1%81%D0%BA%D0%B8%D1%85,_%D0%B2_%D0%BA%D0%BE%D1%82%D0%BE%D1%80%D1%8B%D0%B5_%D0%B2%D0%B5%D1%80%D1%8F%D1%82_%D0%B0%D0%BC%D0%B5%D1%80%D0%B8%D0%BA%D0%B0%D0%BD%D1%86%D1%8B\n",
    "\n",
    "https://dzen.ru/a/ZfHtqQPJj3LVcVWV\n",
    "\n",
    "https://www.reddit.com/r/AskCentralAsia/comments/ahes8h/what_are_the_stereotypes_of_the_different_central/?tl=ru\n",
    "\n",
    "https://am.tsargrad.tv/articles/5-stereotipov-pro-armjan-i-armeniju_395939\n",
    "\n",
    "https://adme.media/articles/ya-zhivu-v-irane-i-hochu-rasskazat-o-10-veschah-kotorye-otkroyut-etu-stranu-s-drugoj-storony-1859715/\n",
    "\n",
    "https://chilltravel.ru/iindiastereotipi\n",
    "\n",
    "https://www.chaochay.ru/blog/9-mifov-o-kitae-i-kitajcah\n",
    "\n",
    "https://smapse.ru/7-banalnyh-stereotipov-o-zhitelyah-yuzhnoj-korei/\n",
    "\n",
    "https://lifehacker.ru/stereotipy-o-severnoi-koree/\n",
    "\n",
    "https://moya-planeta.ru/reports/view/yaponcy_lomka_stereotipov_35074\n",
    "\n",
    "https://smapse.ru/15-stereotipov-o-yaponcah-kotorye-oni-nenavidyat/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70db2df",
   "metadata": {},
   "source": [
    "LGBTQ+ Stereotypes\n",
    "\n",
    "https://denis-balin.livejournal.com/329915.html\n",
    "\n",
    "https://sojka.io/ru/guides/lgbt\n",
    "\n",
    "http://raznoobrasije.org/wp-content/uploads/2020/07/2020_Raznoobrasije_1_Mythen-und-Fakten-u%CC%88ber-LGB.pdf\n",
    "\n",
    "https://spherequeer.org/bisexual-week-2023/\n",
    "\n",
    "https://gpress.info/2020/03/13/stereotipy-o-lgbt-1/\n",
    "\n",
    "https://parniplus.com/lgbt-movement/myths-about-bisexuality/\n",
    "\n",
    "\n",
    "https://www.kok.team/ru/2018-04-26/stereotipy-o-lesbiyankah\n",
    "\n",
    "https://yvision.kz/post/gei-i-lesbiyanki-mify-i-fakty-seksualnaya-patologiya-ili-estestvennyy-process-298823\n",
    "\n",
    "https://whatisgood.ru/theory/analytics/ulovki-lgbt-propagand/\n",
    "\n",
    "https://holod.media/2023/05/15/myths-about-trans-people/\n",
    "\n",
    "https://vk.com/@ovsyanart-trans-people\n",
    "\n",
    "https://rostovgazeta.ru/news/2017-02-17/samye-rasprostranennye-mify-o-transgenderah-1353439?utm_source=google.com&utm_medium=organic&utm_campaign=google.com&utm_referrer=google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59605bd9",
   "metadata": {},
   "source": [
    "## References  - Stereotype\n",
    "\n",
    "[24] Kaustubh Shivshankar Shejole and Pushpak Bhattacharyya. 2025.  \n",
    "StereoDetect: Detecting Stereotypes and Anti-stereotypes the Correct Way  \n",
    "Using Social Psychological Underpinnings. arXiv preprint arXiv:2504.03352.  \n",
    "Available at: https://arxiv.org/abs/2504.03352  \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da557ffe",
   "metadata": {},
   "source": [
    "## References: RuHateBe\n",
    "\n",
    "[6] Anna Palatkina, Elisey Rykov, Elina Sigdel, and Anna Sukhanova. 2024. \n",
    "RUHABE: Russian Hate Speech Benchmark. \n",
    "Available at: https://disk.360.yandex.ru/i/Divcpu7LaJwchw  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[7] Anna Palatkina, Elisey Rykov, Elina Sigdel, and Anna Sukhanova. 2024. \n",
    "RUHABE Dataset. \n",
    "Available at: https://disk.360.yandex.ru/d/hi3PF0XuoyCRlg  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[8] Anna Palatkina, Elisey Rykov, Elina Sigdel, and Anna Sukhanova. 2024. \n",
    "RUHABE Website (GitHub Repository). \n",
    "Available at: https://github.com/Annasuhstuff/RUHABE-website \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f0706",
   "metadata": {},
   "source": [
    "## References: Russian Distorted Toxicity\n",
    "\n",
    "[12] Alla Goryacheva. 2023. Toxicity Detection in Russian: Thesis Project Repository.  \n",
    "GitHub Repository. Available at: https://github.com/alla-g/toxicity-detection-thesis/  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[13] Alla Goryacheva. 2023. Russian Distorted Toxicity Corpus (TSV file).  \n",
    "In *Toxicity Detection in Russian: Thesis Project Repository*.  \n",
    "Available at: https://github.com/alla-g/toxicity-detection-thesis/blob/main/toxicity_corpus/russian_distorted_toxicity.tsv  \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8990f5",
   "metadata": {},
   "source": [
    "## References: Kaggle - Russian Language Toxic Comments\n",
    "\n",
    "[14] Blackmoon. 2019. Russian Language Toxic Comments Dataset.  \n",
    "Kaggle. Available at: https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[15] Sergey Smetanin. 2020. Toxic Comments Detection in Russian.  \n",
    "In *Computational Linguistics and Intellectual Technologies: Proceedings of the International Conference “Dialogue 2020”*.  \n",
    "Available at: https://doi.org/10.28995/2075-7182-2020-19-1149-1159  \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425235a9",
   "metadata": {},
   "source": [
    "## References: Kaggle - Russian Hate Speech Recognition\n",
    "\n",
    "[23] Kamil Saitov and Leon Derczynski. 2021.  \n",
    "Abusive Language Recognition in Russian.  \n",
    "In *Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing*,  \n",
    "Kiyv, Ukraine, 20–25. Association for Computational Linguistics.  \n",
    "Available at: https://aclanthology.org/2021.bsnlp-1.3/  \n",
    "(Accessed: 7 December 2025).\n",
    "\n",
    "[20] Kamil Saitov and Leon Derczynski. 2021.   \n",
    "Russian Hate Speech Recognition (GitHub Repository).  \n",
    "Available at: https://github.com/Sariellee/Russan-Hate-speech-Recognition \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9678ac",
   "metadata": {},
   "source": [
    "## References: Kaggle - Misc\n",
    "\n",
    "[16] Bertie Vidgen and Leon Derczynski. 2020.  \n",
    "Directions in abusive language training data, a systematic review: Garbage in, garbage out.  \n",
    "*PLOS ONE*, 15, 12, e0243300.  \n",
    "Available at: https://doi.org/10.1371/journal.pone.0243300  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[17] Fabio Poletto, Valerio Basile, Manuela Sanguinetti, Cristina Bosco, and Viviana Patti. 2021.  \n",
    "Resources and benchmark corpora for hate speech detection: A systematic review.  \n",
    "*Language Resources & Evaluation*, 55, 477–523.  \n",
    "Available at: https://doi.org/10.1007/s10579-020-09502-8  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[18] Surendrabikram Thapa, Aditya Shah, Farhan Jafri, Usman Naseem, and Imran Razzak. 2022.  \n",
    "A Multi-Modal Dataset for Hate Speech Detection on Social Media: Case-study of Russia–Ukraine Conflict.  \n",
    "In *Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE)*,  \n",
    "1–6. Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.  \n",
    "Available at: https://aclanthology.org/2022.case-1.1  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[19] Surendrabikram Thapa, Farhan Ahmad Jafri, Kritesh Rauniyar, Mehwish Nasim, and Usman Naseem. 2024.  \n",
    "RUHate-MM: Identification of Hate Speech and Targets using Multimodal Data from Russia–Ukraine Crisis.  \n",
    "In *Companion Proceedings of the ACM Web Conference 2024 (WWW '24)*.  \n",
    "Association for Computing Machinery, New York, NY, USA, 1854–1863.  \n",
    "Available at: https://doi.org/10.1145/3589335.3651973  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[21] Ekaterina Pronoza, Polina Panicheva, Olessia Koltsova, and Paolo Rosso. 2021.  \n",
    "Detecting ethnicity-targeted hate speech in Russian social media texts.  \n",
    "Information Processing & Management, 58, 6 (2021), 102674.  \n",
    "Available at: https://www.sciencedirect.com/science/article/pii/S0306457321001606  \n",
    "(Accessed: 6 December 2025).  \n",
    "https://doi.org/10.1016/j.ipm.2021.102674\n",
    "\n",
    "[22] X. Wen, Y. Wang, K. Wang, and R. Sui. 2022.  \n",
    "A Russian Hate Speech Corpus for Cybersecurity Applications.  \n",
    "In *Proceedings of the 2022 IEEE 8th International Conference on Big Data Security on Cloud (BigDataSecurity),  \n",
    "IEEE International Conference on High Performance and Smart Computing (HPSC) and  \n",
    "IEEE International Conference on Intelligent Data and Security (IDS)*, Jinan, China, 41–47.  \n",
    "Available at: https://doi.org/10.1109/BigDataSecurityHPSCIDS54978.2022.00018  \n",
    "(Accessed: 6 December 2025)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (GPU)",
   "language": "python",
   "name": "hearts_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
