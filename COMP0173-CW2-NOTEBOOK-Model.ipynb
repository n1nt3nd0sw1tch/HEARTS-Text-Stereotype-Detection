{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c925ac8a",
   "metadata": {},
   "source": [
    "# COMP0173: Coursework 2\n",
    "\n",
    "The paper HEARTS: A Holistic Framework for Explainable, Sustainable, and Robust Text Stereotype Detection by Theo King, Zekun Wu et al. (2024) presents a comprehensive approach to analysing and detecting stereotypes in text [1]. The authors introduce the HEARTS framework, which integrates model explainability, carbon-efficient training, and accurate evaluation across multiple bias-sensitive datasets. By using transformer-based models such as ALBERT-V2, BERT, and DistilBERT, this research project demonstrates that stereotype detection performance varies significantly across dataset sources, underlining the need for diverse evaluation benchmarks. The paper provides publicly available datasets and code [2], allowing full reproducibility and offering a standardised methodology for future research on bias and stereotype detection in Natural Language Processing (NLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068fd33",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "All figures produced during this notebook are stored in the project’s `/COMP0173_Figures` directory.\n",
    "The corresponding LaTeX-formatted performance comparison tables, including ALBERT-V2, BERT, and DistilBERT are stored in `/COMP0173_PDF`, with the compiled document available as `COMP0173-CW2-TABLES.pdf`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279720f4",
   "metadata": {},
   "source": [
    "# Technical Implementation (70%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526aa252-67bc-4800-a639-661ef2b90b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import random, numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import importlib.util, pathlib\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "from importlib import reload\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import platform\n",
    "# import transformers\n",
    "# from datasets import load_dataset\n",
    "# import spacy \n",
    "\n",
    "# # Check the GPU host (UCL access)\n",
    "# print(\"CUDA available:\", torch.cuda.is_available())\n",
    "# print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# # Path\n",
    "# import os\n",
    "# os.chdir(\"/tmp/HEARTS-Text-Stereotype-Detection\")\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ddc52",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Part 2: Identify a contextually relevant challenge in your country or region of your choice that can be addressed using the same AI approach\n",
    "\n",
    "**Content Warning:**\n",
    "This notebook contains examples of stereotypes and anti-stereotypes that\n",
    "may be offensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798713bb",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 1:}$ Problem and SDG alignment\n",
    "\n",
    "This coursework supports Sustainable Development Goal (SDG) 5: Gender Equality - *Achieve gender equality and empower all women and girls*, SDG 9: Industry, Innovation, and Infrastructure - *Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation*, SDG 10: Reduced Inequalities - *Reduce inequality within and among countries*, and SDG 16: Peace, Justice, and Strong Institutions: - *Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels* [5].\n",
    "\n",
    "The specific targets covered by this coursework are:\n",
    "\n",
    "- SDG 5.1: *End all forms of discrimination against all women and girls everywhere*\n",
    "\n",
    "- SDG 5.b: *Enhance the use of enabling technology, in particular information and communications technology, to promote the empowerment of women*\n",
    "\n",
    "- SDG 10.2: *By 2030, empower and promote the social, economic and political inclusion of all, irrespective of age, sex, disability, race, ethnicity, origin, religion or economic or other status*\n",
    "\n",
    "- SDG 10.3: *Ensure equal opportunity and reduce inequalities of outcome, including by eliminating discriminatory laws, policies and practices and promoting appropriate legislation, policies and action in this regard*\n",
    "\n",
    "- SDG 16.1: *Significantly reduce all forms of violence and related death rates everywhere*\n",
    "\n",
    "- SDG 16.6: *Develop effective, accountable and transparent institutions at all levels*\n",
    "\n",
    "- SDG 16.10: *Ensure public access to information and protect fundamental freedoms, in accordance with national legislation and international agreements*\n",
    "\n",
    "- SDG 16.b: *Promote and enforce non-discriminatory laws and policies for sustainable development*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf01c4",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 2:}$ Limitations and ethical considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f71d69",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 3:}$ Scalability and sustainability analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00197cf",
   "metadata": {},
   "source": [
    "## Part 3: Curate or identify an alternative dataset appropriate for your context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ef1ca",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 1:}$ Identify contextually appropriate dataset\n",
    "\n",
    "1. RuBias\n",
    "2. Kaggle\n",
    "3. RuHateBe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b59f2",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 2:}$ Document data collection/access process and ethical considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9d969",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 3:}$ Provide data preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b406ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets in their raw format \n",
    "\n",
    "# RuBias\n",
    "rubias = pd.read_csv(\"COMP0173_Data/rubias.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Kaggle\n",
    "kaggle = pd.read_csv(\"COMP0173_Data/kaggle.csv\")\n",
    "\n",
    "# RuHaBe\n",
    "ruhabe = pd.read_csv(\"COMP0173_Data/ruhabe.csv\", sep=\";\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b62b129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'pro-trope', 'anti-trope', 'domain', 'task_type'], dtype='object')\n",
      "(2221, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2221 entries, 0 to 2220\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2221 non-null   int64 \n",
      " 1   pro-trope   2221 non-null   object\n",
      " 2   anti-trope  2221 non-null   object\n",
      " 3   domain      2221 non-null   object\n",
      " 4   task_type   2221 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 86.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the shape\n",
    "print(rubias.columns)\n",
    "print(rubias.shape)\n",
    "rubias.head()\n",
    "\n",
    "# Display the general information and variable type of the dataset\n",
    "rubias.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b778da",
   "metadata": {},
   "source": [
    "#### RuBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f4682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e909aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"COMP0173_CSV\") / \"rubia.tsv\"\n",
    "\n",
    "# Load data\n",
    "rubia = pd.read_csv(DATA_PATH, sep=\"\\t\")\n",
    "\n",
    "print(rubia.columns)\n",
    "print(rubia.shape)\n",
    "rubia.head()\n",
    "\n",
    "\n",
    "# Convert to string & strip spaces\n",
    "for col in [\"pro-trope\", \"anti-trope\", \"domain\"]:\n",
    "    rubia[col] = rubia[col].astype(str).str.strip()\n",
    "    \n",
    "# Drop rows where pro-trope is missing or empty\n",
    "rubia = rubia[rubia[\"pro-trope\"].str.len() > 0].copy()\n",
    "\n",
    "# Drop exact duplicate pro-trope sentences\n",
    "rubia = rubia.drop_duplicates(subset=[\"pro-trope\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"After cleaning:\", rubia.shape)\n",
    "rubia[\"domain\"].value_counts()\n",
    "\n",
    "rubia\n",
    "\n",
    "\n",
    "keep_domains = [\"gender\", \"lgbtq\", \"nationality\", \"Other\"]  # adjust if needed\n",
    "df_raw = df_raw[df_raw[\"domain\"].isin(keep_domains)].reset_index(drop=True)\n",
    "\n",
    "print(\"After domain filter:\", df_raw.shape)\n",
    "df_raw[\"domain\"].value_counts()\n",
    "\n",
    "\n",
    "# Give each row a unique integer ID\n",
    "df_raw[\"seed_id\"] = range(len(df_raw))\n",
    "\n",
    "df_stereo_base = pd.DataFrame({\n",
    "    \"seed_id\": df_raw[\"seed_id\"],\n",
    "    \"text\": df_raw[\"pro-trope\"],\n",
    "    \"group\": df_raw[\"domain\"],\n",
    "    \"category\": \"stereotype\",               # HEARTS label\n",
    "    \"source\": \"rubia_pro_trope\"\n",
    "})\n",
    "\n",
    "df_stereo_base.head(), df_stereo_base.shape\n",
    "\n",
    "\n",
    "SEED_OUT = \"rubia_stereotype_seeds_for_gpt.csv\"\n",
    "df_stereo_base[[\"seed_id\", \"group\", \"text\"]].to_csv(SEED_OUT, index=False)\n",
    "print(\"Saved seeds to\", SEED_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d02616",
   "metadata": {},
   "source": [
    "#### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd0f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4106dfbc",
   "metadata": {},
   "source": [
    "#### RuHateBe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"COMP0173_Data/ruhabe.csv\", sep=\";\", engine=\"python\")\n",
    "\n",
    "df['target_group'].unique()\n",
    "\n",
    "other_rows = df[df['target_group'] == 'other']\n",
    "other_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf84d7",
   "metadata": {},
   "source": [
    "## Part 4: Adapt the model architecture and training pipeline to your local context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0326e",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 1:}$ Justify architectural modifications for new context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40842ea4",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 2:}$ Document hyperparameter tuning process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d59de",
   "metadata": {},
   "source": [
    "## Part 5: Evaluate the adapted model, comparing performance metrics with the original study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6f894",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 1:}$ Compare original vs. adapted model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0eb46",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 2:}$ Use appropriate metrics for problem type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc9723",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 3:}$ Conduct statistical significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a40030",
   "metadata": {},
   "source": [
    "### $\\color{pink}{Question\\ 4:}$ Analyze failure cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad2c76",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "[1] Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, and Philip Treleaven. 2024.\n",
    "HEARTS: A holistic framework for explainable, sustainable and robust text stereotype detection.\n",
    "arXiv preprint arXiv:2409.11579.\n",
    "Available at: https://arxiv.org/abs/2409.11579\n",
    "(Accessed: 4 December 2025).\n",
    "https://doi.org/10.48550/arXiv.2409.11579\n",
    "\n",
    "[2] Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, and Philip Treleaven. 2024.\n",
    "HEARTS-Text-Stereotype-Detection (GitHub Repository).\n",
    "Available at: https://github.com/holistic-ai/HEARTS-Text-Stereotype-Detection\n",
    "(Accessed: 4 December 2025).\n",
    "\n",
    "[3] Theo King, Zekun Wu, Adriano Koshiyama, Emre Kazim, and Philip Treleaven. Holistic AI. 2024.\n",
    "EMGSD: Expanded Multi-Group Stereotype Dataset (HuggingFace Dataset).\n",
    "Available at: https://huggingface.co/datasets/holistic-ai/EMGSD\n",
    "(Accessed: 4 December 2025).\n",
    "\n",
    "[4] University College London Technical Support Group (TSG).\n",
    "2025. GPU Access and Usage Documentation.\n",
    "Available at: https://tsg.cs.ucl.ac.uk/gpus/\n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[5] United Nations. 2025. The 2030 Agenda for Sustainable Development. \n",
    "Available at: https://sdgs.un.org/2030agenda \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[6] Dominique Geissler, Abdurahman Maarouf, and Stefan Feuerriegel. 2025. Analyzing User Characteristics of Hate Speech Spreaders on Social Media. In Proceedings of the ACM on Web Conference 2025 (WWW '25). Association for Computing Machinery, New York, NY, USA, 5085–5095. https://doi.org/10.1145/3696410.3714502\n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59605bd9",
   "metadata": {},
   "source": [
    "## References  - Stereotype\n",
    "\n",
    "[24] Kaustubh Shivshankar Shejole and Pushpak Bhattacharyya. 2025.  \n",
    "StereoDetect: Detecting Stereotypes and Anti-stereotypes the Correct Way  \n",
    "Using Social Psychological Underpinnings. arXiv preprint arXiv:2504.03352.  \n",
    "Available at: https://arxiv.org/abs/2504.03352  \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da557ffe",
   "metadata": {},
   "source": [
    "## References: RuHateBe\n",
    "\n",
    "[6] Anna Palatkina, Elisey Rykov, Elina Sigdel, and Anna Sukhanova. 2024. \n",
    "RUHABE: Russian Hate Speech Benchmark. \n",
    "Available at: https://disk.360.yandex.ru/i/Divcpu7LaJwchw  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[7] Anna Palatkina, Elisey Rykov, Elina Sigdel, and Anna Sukhanova. 2024. \n",
    "RUHABE Dataset. \n",
    "Available at: https://disk.360.yandex.ru/d/hi3PF0XuoyCRlg  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[8] Anna Palatkina, Elisey Rykov, Elina Sigdel, and Anna Sukhanova. 2024. \n",
    "RUHABE Website (GitHub Repository). \n",
    "Available at: https://github.com/Annasuhstuff/RUHABE-website \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f0706",
   "metadata": {},
   "source": [
    "## References: Russian Distorted Toxicity\n",
    "\n",
    "[12] Alla Goryacheva. 2023. Toxicity Detection in Russian: Thesis Project Repository.  \n",
    "GitHub Repository. Available at: https://github.com/alla-g/toxicity-detection-thesis/  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[13] Alla Goryacheva. 2023. Russian Distorted Toxicity Corpus (TSV file).  \n",
    "In *Toxicity Detection in Russian: Thesis Project Repository*.  \n",
    "Available at: https://github.com/alla-g/toxicity-detection-thesis/blob/main/toxicity_corpus/russian_distorted_toxicity.tsv  \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8990f5",
   "metadata": {},
   "source": [
    "## References: Kaggle - Russian Language Toxic Comments\n",
    "\n",
    "[14] Blackmoon. 2019. Russian Language Toxic Comments Dataset.  \n",
    "Kaggle. Available at: https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[15] Sergey Smetanin. 2020. Toxic Comments Detection in Russian.  \n",
    "In *Computational Linguistics and Intellectual Technologies: Proceedings of the International Conference “Dialogue 2020”*.  \n",
    "Available at: https://doi.org/10.28995/2075-7182-2020-19-1149-1159  \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425235a9",
   "metadata": {},
   "source": [
    "## References: Kaggle - Russian Hate Speech Recognition\n",
    "\n",
    "[23] Kamil Saitov and Leon Derczynski. 2021.  \n",
    "Abusive Language Recognition in Russian.  \n",
    "In *Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing*,  \n",
    "Kiyv, Ukraine, 20–25. Association for Computational Linguistics.  \n",
    "Available at: https://aclanthology.org/2021.bsnlp-1.3/  \n",
    "(Accessed: 7 December 2025).\n",
    "\n",
    "[20] Kamil Saitov and Leon Derczynski. 2021.   \n",
    "Russian Hate Speech Recognition (GitHub Repository).  \n",
    "Available at: https://github.com/Sariellee/Russan-Hate-speech-Recognition \n",
    "(Accessed: 6 December 2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9678ac",
   "metadata": {},
   "source": [
    "## References: Kaggle - Misc\n",
    "\n",
    "[16] Bertie Vidgen and Leon Derczynski. 2020.  \n",
    "Directions in abusive language training data, a systematic review: Garbage in, garbage out.  \n",
    "*PLOS ONE*, 15, 12, e0243300.  \n",
    "Available at: https://doi.org/10.1371/journal.pone.0243300  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[17] Fabio Poletto, Valerio Basile, Manuela Sanguinetti, Cristina Bosco, and Viviana Patti. 2021.  \n",
    "Resources and benchmark corpora for hate speech detection: A systematic review.  \n",
    "*Language Resources & Evaluation*, 55, 477–523.  \n",
    "Available at: https://doi.org/10.1007/s10579-020-09502-8  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[18] Surendrabikram Thapa, Aditya Shah, Farhan Jafri, Usman Naseem, and Imran Razzak. 2022.  \n",
    "A Multi-Modal Dataset for Hate Speech Detection on Social Media: Case-study of Russia–Ukraine Conflict.  \n",
    "In *Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE)*,  \n",
    "1–6. Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.  \n",
    "Available at: https://aclanthology.org/2022.case-1.1  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[19] Surendrabikram Thapa, Farhan Ahmad Jafri, Kritesh Rauniyar, Mehwish Nasim, and Usman Naseem. 2024.  \n",
    "RUHate-MM: Identification of Hate Speech and Targets using Multimodal Data from Russia–Ukraine Crisis.  \n",
    "In *Companion Proceedings of the ACM Web Conference 2024 (WWW '24)*.  \n",
    "Association for Computing Machinery, New York, NY, USA, 1854–1863.  \n",
    "Available at: https://doi.org/10.1145/3589335.3651973  \n",
    "(Accessed: 6 December 2025).\n",
    "\n",
    "[21] Ekaterina Pronoza, Polina Panicheva, Olessia Koltsova, and Paolo Rosso. 2021.  \n",
    "Detecting ethnicity-targeted hate speech in Russian social media texts.  \n",
    "Information Processing & Management, 58, 6 (2021), 102674.  \n",
    "Available at: https://www.sciencedirect.com/science/article/pii/S0306457321001606  \n",
    "(Accessed: 6 December 2025).  \n",
    "https://doi.org/10.1016/j.ipm.2021.102674\n",
    "\n",
    "[22] X. Wen, Y. Wang, K. Wang, and R. Sui. 2022.  \n",
    "A Russian Hate Speech Corpus for Cybersecurity Applications.  \n",
    "In *Proceedings of the 2022 IEEE 8th International Conference on Big Data Security on Cloud (BigDataSecurity),  \n",
    "IEEE International Conference on High Performance and Smart Computing (HPSC) and  \n",
    "IEEE International Conference on Intelligent Data and Security (IDS)*, Jinan, China, 41–47.  \n",
    "Available at: https://doi.org/10.1109/BigDataSecurityHPSCIDS54978.2022.00018  \n",
    "(Accessed: 6 December 2025)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hearts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
